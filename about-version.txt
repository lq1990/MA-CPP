RNN-01
	naive RNN with 1 hidden layer

RNN-v2-OneHidden
	+ Multi-thread CPU Computing
RNN-v2
	naive RNN with 2 hidden layers
	+ Multi-thread

RNN-v3
	Cuda trial of naive RNN with thrust::device_vector<float>()
RNN-v3.1
	Cuda trial of naive RNN with float* to replace thrust
RNN-v3.2
	use cudaMalloc(Host) instead of cudaMallocManaged
	to speed up

RNN-v4
	based on RNN-v2,
	naive RNN => LSTM
RNN-v4.1
	LSTM, coding that leart from Web
RNN-v4.2 
	encapsulate hidden layer of LSTM, so that multi-hidden layer is easy to new








	